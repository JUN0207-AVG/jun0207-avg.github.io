import cv2
import mediapipe as mp
import numpy as np
import csv  # æ–°å¢ï¼šåŒ¯å‡ºç”¨

# åˆå§‹åŒ– MediaPipe Pose æ¨¡çµ„
mp_pose = mp.solutions.pose
pose = mp_pose.Pose(min_detection_confidence=0.5,
                    min_tracking_confidence=0.5)
mp_drawing = mp.solutions.drawing_utils
drawing_spec = mp.solutions.drawing_styles.get_default_pose_landmarks_style()
pose_connections = mp_pose.POSE_CONNECTIONS

# å½±ç‰‡èˆ‡æ”å½±æ©Ÿ
cap_video = cv2.VideoCapture('ã€Šé’æ˜¥æœ‰ä½ 2ã€‹ä¸»é¡Œæ›²ã€ŠYESï¼OKï¼ã€‹èˆå°onetakeç›´æ‹â€”â€”åŠ‰é›¨æ˜•ï½œæ„›å¥‡è—å°ç£ç«™.mp4')
cap_cam = cv2.VideoCapture(0)

# å˜—è©¦è®€å–å½±ç‰‡ç¬¬ä¸€å¹€
success, first_frame = cap_video.read()
if not success:
    print("âŒ ç„¡æ³•è®€å–å½±ç‰‡ã€‚")
    cap_video.release()
    exit()

# ç¸®æ”¾è¨­å®š
scale = 0.5
frame_height, frame_width = first_frame.shape[:2]
target_size = (int(frame_width * scale), int(frame_height * scale))

# è©•åˆ†ç´€éŒ„é™£åˆ—ï¼ˆæ–°ï¼‰
score_list = []

# è©•åˆ†å‡½æ•¸
def calculate_pose_similarity(landmarks1, landmarks2, w, h):
    if not landmarks1 or not landmarks2:
        return 0.0
    total_dist = 0
    count = 0
    for i in range(len(landmarks1)):
        x1, y1 = landmarks1[i].x * w, landmarks1[i].y * h
        x2, y2 = landmarks2[i].x * w, landmarks2[i].y * h
        dist = np.sqrt((x1 - x2)**2 + (y1 - y2)**2)
        total_dist += dist
        count += 1
    avg_dist = total_dist / count if count > 0 else 1e9
    score = max(0, 100 - avg_dist * 0.2)
    return round(score, 1)

# ä¸»è¿´åœˆ
frame_index = 0  # å¹€æ•¸è¨ˆæ•¸å™¨
while cap_video.isOpened() and cap_cam.isOpened():
    ret_vid, frame_vid = cap_video.read()
    ret_cam, frame_cam = cap_cam.read()
    if not ret_vid or not ret_cam:
        print("âœ… æ’­æ”¾å®Œç•¢æˆ–æ”å½±æ©Ÿç•°å¸¸")
        break

    # ç¸®å°ç•«é¢
    frame_vid = cv2.resize(frame_vid, target_size)
    frame_cam = cv2.resize(frame_cam, target_size)
    h, w = frame_vid.shape[:2]

    # å»ºç«‹é»‘åº•ç•«å¸ƒ
    bkb_vid = np.zeros_like(frame_vid)
    bkb_cam = np.zeros_like(frame_cam)

    # è™•ç†å½±ç‰‡éª¨æ¶
    result_vid = pose.process(cv2.cvtColor(frame_vid, cv2.COLOR_BGR2RGB))
    if result_vid.pose_landmarks:
        mp_drawing.draw_landmarks(frame_vid, result_vid.pose_landmarks, pose_connections, drawing_spec)
        mp_drawing.draw_landmarks(bkb_vid, result_vid.pose_landmarks, pose_connections, drawing_spec)

    # è™•ç†æ”å½±æ©Ÿéª¨æ¶
    result_cam = pose.process(cv2.cvtColor(frame_cam, cv2.COLOR_BGR2RGB))
    if result_cam.pose_landmarks:
        mp_drawing.draw_landmarks(frame_cam, result_cam.pose_landmarks, pose_connections, drawing_spec)
        mp_drawing.draw_landmarks(bkb_cam, result_cam.pose_landmarks, pose_connections, drawing_spec)

    # è¨ˆç®—è©•åˆ†
    score = 0
    if result_vid.pose_landmarks and result_cam.pose_landmarks:
        score = calculate_pose_similarity(
            result_vid.pose_landmarks.landmark,
            result_cam.pose_landmarks.landmark,
            w, h
        )
        score_list.append((frame_index, score))  # â• ç´€éŒ„åˆ°åˆ—è¡¨ä¸­

    # åˆæˆç•«é¢
    top_row = np.hstack((frame_vid, frame_cam))
    bottom_row = np.hstack((bkb_vid, bkb_cam))
    final_frame = np.vstack((top_row, bottom_row))

    # é¡¯ç¤ºè©•åˆ†
    cv2.putText(final_frame, f'Score: {score}/100', (30, 50),
                cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 3)

    cv2.imshow('æœŸæœ«å ±å‘Šï¼šéª¨æ¶è©•åˆ†ç³»çµ±', final_frame)

    frame_index += 1  # å¹€æ•¸ +1
    if cv2.waitKey(1) & 0xFF == 27:
        print("ğŸ”š æ‰‹å‹•çµæŸã€‚")
        break

# é‡‹æ”¾è³‡æº
cap_video.release()
cap_cam.release()
cv2.destroyAllWindows()

# === åŒ¯å‡ºåˆ†æ•¸è³‡æ–™åˆ° CSV ===
FPS = 30  # å¦‚æœä½ çš„å½±ç‰‡æ˜¯ 30fpsï¼Œé€™è£¡è¨­å®š 30

with open('scores1.csv', 'w', newline='', encoding='utf-8') as f:
    writer = csv.writer(f)
    writer.writerow(['Frame', 'Time(sec)', 'Score'])
    for frame, score in score_list:
        time_sec = round(frame / FPS, 2)
        writer.writerow([frame, time_sec, score])

print("âœ… åˆ†æ•¸å·²å„²å­˜ç‚º scores1.csv")

import csv

lowest_score = float('inf')
lowest_frame = 0
lowest_time = 0

FPS = 30  # å¦‚æœä½ çš„å½±ç‰‡æ˜¯ 30 FPS

with open('scores1.csv', 'r', encoding='utf-8') as f:
    reader = csv.DictReader(f)
    for row in reader:
        score = float(row['Score'])
        frame = int(row['Frame'])
        time = float(row['Time(sec)'])
        if score < lowest_score:
            lowest_score = score
            lowest_frame = frame
            lowest_time = time

print(f"æœ€ä½åˆ†æ•¸ï¼š{lowest_score}ï¼ŒFrameï¼š{lowest_frame}ï¼Œæ™‚é–“ï¼šç´„ {lowest_time:.2f} ç§’")

import cv2

# å½±ç‰‡è¼‰å…¥
video_path = 'ã€Šé’æ˜¥æœ‰ä½ 2ã€‹ä¸»é¡Œæ›²ã€ŠYESï¼OKï¼ã€‹èˆå°onetakeç›´æ‹â€”â€”åŠ‰é›¨æ˜•ï½œæ„›å¥‡è—å°ç£ç«™.mp4'
cap = cv2.VideoCapture(video_path)

# è·³åˆ°æœ€ä½åˆ†çš„ frame
cap.set(cv2.CAP_PROP_POS_FRAMES, lowest_frame)

# è®€å–è©²å¹€
ret, frame = cap.read()
if ret:
    # é¡¯ç¤ºç•«é¢
    cv2.imshow('æœ€ä½åˆ†æ•¸ç•«é¢', frame)
    # å„²å­˜æˆªåœ–
    cv2.imwrite('worst_frame.jpg', frame)
    print("âœ… å·²å„²å­˜ç•«é¢ç‚º worst_frame.jpg")
    cv2.waitKey(0)
else:
    print("âŒ ç„¡æ³•è®€å–è©²å¹€")



cap.release()
cv2.destroyAllWindows()
